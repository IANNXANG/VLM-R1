# R1-V: Reinforce Super Generalization Ability in VLMs with Less Than $3


1. We find out that reinforcement learning with verifiable rewards demonstrates superior effectiveness compared to chain-of-thought supervised fine-tuning(CoT-SFT) on multimodal large language models.
2. 2B model beats 72B model within 100 training steps. 
3. Training is done in 8xA100 GPU for 30 minutes, costing $2.62.
4. Promise: Codes,models,datasets,and truly open-source resources are coming soon.

![image](./images/ood.png)

![image](./images/super_ood.png)

> Contributors: Liang Chen, Lei Li, Haozhe Zhao, Yifan Song

