# R1-V: Reinforce Super Generalization Ability in VLMs with Less Than $3


1. We find out that Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates superior effectiveness and OOD robustness compared to chain-of-thought supervised fine-tuning (CoT-SFT) for large vision language models.
2. 2B model beats 72B model within 100 training steps. 
3. Training is done in 8xA100s GPU for 30 minutes, costing $2.62.
4. Promise: Codes,models,datasets,and truly open-source resources are coming soon.

![image](./images/ood.png)

![image](./images/super_ood.png)

![image](./images/training.png)

> Contributors: Liang Chen, Lei Li, Haozhe Zhao, Yifan Song

