#!/usr/bin/env python3
"""
å•ä¸ªLoRAæ¨¡å‹åˆå¹¶è„šæœ¬ - ç”¨äºé€ä¸ªåˆå¹¶æ¨¡å‹ä»¥é¿å…å†…å­˜é—®é¢˜
"""

import os
import sys
import argparse
from pathlib import Path
from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor
from peft import PeftModel
import torch

def merge_single_lora(lora_checkpoint_path, base_model_path, output_path):
    """
    åˆå¹¶å•ä¸ªLoRAæ¨¡å‹
    """
    print(f"LoRAæ£€æŸ¥ç‚¹: {lora_checkpoint_path}")
    print(f"åŸºç¡€æ¨¡å‹: {base_model_path}")
    print(f"è¾“å‡ºè·¯å¾„: {output_path}")
    
    # æ£€æŸ¥è·¯å¾„
    if not os.path.exists(lora_checkpoint_path):
        print(f"é”™è¯¯: LoRAæ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {lora_checkpoint_path}")
        return False
    
    if not os.path.exists(base_model_path):
        print(f"é”™è¯¯: åŸºç¡€æ¨¡å‹ä¸å­˜åœ¨: {base_model_path}")
        return False
    
    adapter_config_path = os.path.join(lora_checkpoint_path, "adapter_config.json")
    if not os.path.exists(adapter_config_path):
        print(f"é”™è¯¯: æœªæ‰¾åˆ°adapter_config.json: {adapter_config_path}")
        return False
    
    try:
        print("\n1. åŠ è½½åŸºç¡€æ¨¡å‹...")
        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            base_model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
        print("âœ“ åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ")
        
        print("\n2. åŠ è½½LoRAé€‚é…å™¨...")
        model = PeftModel.from_pretrained(
            base_model,
            lora_checkpoint_path,
            torch_dtype=torch.bfloat16
        )
        print("âœ“ LoRAé€‚é…å™¨åŠ è½½å®Œæˆ")
        
        print("\n3. åˆå¹¶LoRAæƒé‡...")
        merged_model = model.merge_and_unload()
        print("âœ“ LoRAæƒé‡åˆå¹¶å®Œæˆ")
        
        print("\n4. åˆ›å»ºè¾“å‡ºç›®å½•...")
        os.makedirs(output_path, exist_ok=True)
        print(f"âœ“ è¾“å‡ºç›®å½•åˆ›å»º: {output_path}")
        
        print("\n5. ä¿å­˜åˆå¹¶åçš„æ¨¡å‹...")
        merged_model.save_pretrained(
            output_path,
            safe_serialization=True,
            max_shard_size="5GB"
        )
        print("âœ“ æ¨¡å‹ä¿å­˜å®Œæˆ")
        
        print("\n6. ä¿å­˜tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(base_model_path)
        tokenizer.save_pretrained(output_path)
        print("âœ“ Tokenizerä¿å­˜å®Œæˆ")
        
        print("\n7. ä¿å­˜processor...")
        try:
            processor = AutoProcessor.from_pretrained(base_model_path)
            processor.save_pretrained(output_path)
            print("âœ“ Processorä¿å­˜å®Œæˆ")
        except Exception as e:
            print(f"âš  Processorä¿å­˜å¤±è´¥ (å¯å¿½ç•¥): {e}")
        
        print(f"\nğŸ‰ æˆåŠŸåˆå¹¶æ¨¡å‹åˆ°: {output_path}")
        return True
        
    except Exception as e:
        print(f"\nâŒ åˆå¹¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†å†…å­˜
        print("\n8. æ¸…ç†å†…å­˜...")
        if 'base_model' in locals():
            del base_model
        if 'model' in locals():
            del model
        if 'merged_model' in locals():
            del merged_model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print("âœ“ å†…å­˜æ¸…ç†å®Œæˆ")

def main():
    parser = argparse.ArgumentParser(description="åˆå¹¶å•ä¸ªLoRAæ¨¡å‹")
    parser.add_argument("--lora_path", required=True, help="LoRAæ£€æŸ¥ç‚¹è·¯å¾„")
    parser.add_argument("--base_model", default="/c22940/zy/model/Qwen2.5-VL-7B-Instruct", help="åŸºç¡€æ¨¡å‹è·¯å¾„")
    parser.add_argument("--output_path", required=True, help="è¾“å‡ºè·¯å¾„")
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("LoRAæ¨¡å‹åˆå¹¶å·¥å…·")
    print("=" * 80)
    
    success = merge_single_lora(args.lora_path, args.base_model, args.output_path)
    
    if success:
        print("\nâœ… åˆå¹¶æˆåŠŸ!")
        print(f"åˆå¹¶åçš„å®Œæ•´æ¨¡å‹ä¿å­˜åœ¨: {args.output_path}")
        print("ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™ä¸ªå®Œæ•´æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚")
        sys.exit(0)
    else:
        print("\nâŒ åˆå¹¶å¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()